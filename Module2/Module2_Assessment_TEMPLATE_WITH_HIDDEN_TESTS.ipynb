{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcfef08",
   "metadata": {},
   "source": "# Module 2 – Python for Data Work Assessment (Instructor Version)\n\n**Instructor / Grading Template**\n\nThis notebook contains **hidden assessment logic** and must NOT be shared with students.\n\nPurpose:\n- Inject student code programmatically\n- Run automated tests\n- Produce authoritative scores\n\n**Assessment Data Sources:**\nStudents must download real data from:\n1. DJIA from WSJ or Yahoo Finance -> `djia_data.csv`\n2. USD/GBP from FRED (DEXUSUK) -> `fx_usd_gbp.csv`  \n3. Federal Funds Rate from FRED (FEDFUNDS) -> `fed_funds_rate.csv`\n\n**Total Points:** 100 (20 points per task)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740cd89d",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN: SCORING SETUP ===\n__assessment_scores = {}\n__assessment_feedback = {}\n\ndef record_score(exercise, points, max_points, feedback=None):\n    __assessment_scores[exercise] = (points, max_points)\n    if feedback:\n        __assessment_feedback[exercise] = feedback"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN: IMPORTS FOR TESTING ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 10)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task1-header",
   "metadata": {},
   "source": [
    "## Task 1 — Load & Inspect DJIA (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task1-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 1 ===\n# Tests loading REAL DJIA data from djia_data.csv\npoints = 0\nfeedback = []\n\n# Helper to find column by normalized name\ndef find_col(df, name):\n    for c in df.columns:\n        if c.strip().lower() == name.lower():\n            return c\n    return None\n\ntry:\n    # Check djia_df exists\n    assert 'djia_df' in globals() or 'djia_df' in dir(), \"djia_df not defined\"\n    points += 5\n    feedback.append(\"✓ djia_df variable created\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Error checking djia_df: {type(e).__name__}\")\n\ntry:\n    # Check required columns (flexible: strip whitespace, case-insensitive)\n    required_cols = {'date', 'open', 'high', 'low', 'close'}\n    actual_cols_normalized = {c.strip().lower() for c in djia_df.columns}\n    missing = required_cols - actual_cols_normalized\n    assert not missing, f\"Missing columns: {missing}. Have: {list(djia_df.columns)}\"\n    points += 5\n    feedback.append(\"✓ All required columns present (Date, Open, High, Low, Close)\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept NameError:\n    feedback.append(\"✗ Cannot check columns - djia_df not defined\")\nexcept Exception as e:\n    feedback.append(f\"✗ Column check error: {type(e).__name__}\")\n\ntry:\n    # Check data is sorted by date (oldest first)\n    date_col = find_col(djia_df, 'date')\n    dates = pd.to_datetime(djia_df[date_col])\n    assert dates.is_monotonic_increasing, \"Data not sorted by date (oldest first)\"\n    points += 5\n    feedback.append(\"✓ Data sorted by date (oldest first)\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Date sorting check failed: {type(e).__name__}\")\n\ntry:\n    # Check Date is datetime type and data has reasonable size\n    date_col = find_col(djia_df, 'date')\n    assert pd.api.types.is_datetime64_any_dtype(djia_df[date_col]), \"Date column not converted to datetime\"\n    assert len(djia_df) >= 100, f\"Only {len(djia_df)} rows - expected 100+ rows of data\"\n    points += 5\n    feedback.append(f\"✓ Date is datetime type, {len(djia_df)} rows loaded\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Date type check failed: {type(e).__name__}\")\n\nrecord_score('Task 1', points, 20, feedback)"
  },
  {
   "cell_type": "markdown",
   "id": "task2-header",
   "metadata": {},
   "source": [
    "## Task 2 — Cleaning & Feature Engineering (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task2-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 2 ===\n# Tests cleaning and feature engineering on real DJIA data\npoints = 0\nfeedback = []\n\n# Helper to find column by normalized name\ndef find_col(df, name):\n    for c in df.columns:\n        if c.strip().lower() == name.lower():\n            return c\n    return None\n\ntry:\n    # Check Date is datetime\n    date_col = find_col(djia_df, 'date')\n    assert pd.api.types.is_datetime64_any_dtype(djia_df[date_col]), \"Date column not datetime type\"\n    points += 5\n    feedback.append(\"✓ Date column is datetime type\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept NameError:\n    feedback.append(\"✗ djia_df not defined - complete Task 1 first\")\nexcept Exception as e:\n    feedback.append(f\"✗ Date type check failed: {type(e).__name__}\")\n\ntry:\n    # Check Daily_Return column exists\n    dr_col = find_col(djia_df, 'daily_return')\n    assert dr_col is not None, \"Daily_Return column not found - did you create it?\"\n    points += 5\n    feedback.append(\"✓ Daily_Return column created\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Daily_Return check failed: {type(e).__name__}\")\n\ntry:\n    # Check Daily_Return has values\n    dr_col = find_col(djia_df, 'daily_return')\n    non_null_count = djia_df[dr_col].notna().sum()\n    total_rows = len(djia_df)\n    assert non_null_count >= total_rows - 5, f\"Daily_Return has too many NaN values ({total_rows - non_null_count} missing)\"\n    points += 5\n    feedback.append(f\"✓ Daily_Return has {non_null_count} valid values\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Daily_Return values check failed: {type(e).__name__}\")\n\ntry:\n    # Check Daily_Return is reasonable\n    dr_col = find_col(djia_df, 'daily_return')\n    mean_abs_return = djia_df[dr_col].abs().mean()\n    assert 0.01 < mean_abs_return < 5, f\"Daily_Return values seem wrong (mean abs = {mean_abs_return:.2f}%)\"\n    points += 5\n    feedback.append(f\"✓ Daily_Return values reasonable (mean abs = {mean_abs_return:.2f}%)\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Daily_Return validation failed: {type(e).__name__}\")\n\nrecord_score('Task 2', points, 20, feedback)"
  },
  {
   "cell_type": "markdown",
   "id": "task3-header",
   "metadata": {},
   "source": [
    "## Task 3 — Visual Analysis (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task3-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 3 ===\n# Visual tasks - award points for having the data ready for plotting\npoints = 0\nfeedback = []\n\n# Helper to find column by normalized name\ndef find_col(df, name):\n    for c in df.columns:\n        if c.strip().lower() == name.lower():\n            return c\n    return None\n\ntry:\n    # Check djia_df exists with Close column for plotting\n    assert 'djia_df' in globals(), \"djia_df not defined\"\n    close_col = find_col(djia_df, 'close')\n    assert close_col is not None, \"Close column not found for time-series plot\"\n    assert len(djia_df) > 0, \"djia_df is empty\"\n    points += 10\n    feedback.append(\"✓ Close price data available for time-series plot\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Close column check failed: {type(e).__name__}\")\n\ntry:\n    # Check Daily_Return exists for histogram\n    dr_col = find_col(djia_df, 'daily_return')\n    assert dr_col is not None, \"Daily_Return column not found for histogram\"\n    valid_count = djia_df[dr_col].notna().sum()\n    assert valid_count > 0, \"Daily_Return has no valid values for histogram\"\n    points += 10\n    feedback.append(f\"✓ Daily_Return data available for histogram ({valid_count} values)\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Daily_Return check failed: {type(e).__name__}\")\n\nrecord_score('Task 3', points, 20, feedback)"
  },
  {
   "cell_type": "markdown",
   "id": "task4-header",
   "metadata": {},
   "source": [
    "## Task 4 — Multi-Dataset Analysis (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task4-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 4 ===\n# Tests loading REAL FX data from FRED (fx_usd_gbp.csv)\npoints = 0\nfeedback = []\n\n# Helper to find column by normalized name\ndef find_col(df, name):\n    for c in df.columns:\n        if c.strip().lower() == name.lower():\n            return c\n    return None\n\ntry:\n    # Check fx_df exists\n    assert 'fx_df' in globals(), \"fx_df not defined - did you load fx_usd_gbp.csv?\"\n    points += 5\n    feedback.append(\"✓ fx_df variable created\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ fx_df check failed: {type(e).__name__}\")\n\ntry:\n    # Check required columns\n    date_col = find_col(fx_df, 'date')\n    usd_col = find_col(fx_df, 'usd_gbp')\n    fx_ret_col = find_col(fx_df, 'fx_return')\n    missing = []\n    if date_col is None: missing.append('Date')\n    if usd_col is None: missing.append('USD_GBP')\n    if fx_ret_col is None: missing.append('FX_Return')\n    assert not missing, f\"Missing columns: {missing}\"\n    points += 5\n    feedback.append(\"✓ All required columns present (Date, USD_GBP, FX_Return)\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept NameError:\n    feedback.append(\"✗ fx_df not defined\")\nexcept Exception as e:\n    feedback.append(f\"✗ Column check failed: {type(e).__name__}\")\n\ntry:\n    # Check USD_GBP values are reasonable\n    usd_col = find_col(fx_df, 'usd_gbp')\n    mean_rate = fx_df[usd_col].mean()\n    assert 1.0 < mean_rate < 1.6, f\"USD_GBP mean={mean_rate:.3f} outside expected range (1.0-1.6)\"\n    points += 5\n    feedback.append(f\"✓ USD_GBP values reasonable (mean = {mean_rate:.3f})\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ USD_GBP validation failed: {type(e).__name__}\")\n\ntry:\n    # Check Date is datetime and data size\n    date_col = find_col(fx_df, 'date')\n    assert pd.api.types.is_datetime64_any_dtype(fx_df[date_col]), \"Date column not datetime type\"\n    assert len(fx_df) >= 50, f\"Only {len(fx_df)} rows - expected 50+ rows of FX data\"\n    points += 5\n    feedback.append(f\"✓ Date is datetime type, {len(fx_df)} rows loaded\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Date/size check failed: {type(e).__name__}\")\n\nrecord_score('Task 4', points, 20, feedback)"
  },
  {
   "cell_type": "markdown",
   "id": "task5-header",
   "metadata": {},
   "source": [
    "## Task 5 — Macro Insight (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task5-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 5 ===\n# Tests loading REAL Fed Funds Rate data from FRED (fed_funds_rate.csv)\npoints = 0\nfeedback = []\n\n# Helper to find column by normalized name\ndef find_col(df, name):\n    for c in df.columns:\n        if c.strip().lower() == name.lower():\n            return c\n    return None\n\ntry:\n    # Check rates_df exists\n    assert 'rates_df' in globals(), \"rates_df not defined - did you load fed_funds_rate.csv?\"\n    points += 5\n    feedback.append(\"✓ rates_df variable created\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ rates_df check failed: {type(e).__name__}\")\n\ntry:\n    # Check FEDFUNDS column exists and has valid values\n    ff_col = find_col(rates_df, 'fedfunds')\n    assert ff_col is not None, \"FEDFUNDS column not found\"\n    max_rate = rates_df[ff_col].max()\n    assert 0 < max_rate < 10, f\"FEDFUNDS max={max_rate:.2f}% outside expected range (0-10%)\"\n    points += 5\n    feedback.append(f\"✓ FEDFUNDS column present (max rate = {max_rate:.2f}%)\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept NameError:\n    feedback.append(\"✗ rates_df not defined\")\nexcept Exception as e:\n    feedback.append(f\"✗ FEDFUNDS check failed: {type(e).__name__}\")\n\ntry:\n    # Check Date is datetime and data size\n    date_col = find_col(rates_df, 'date')\n    assert pd.api.types.is_datetime64_any_dtype(rates_df[date_col]), \"Date column not datetime type\"\n    assert len(rates_df) >= 12, f\"Only {len(rates_df)} rows - expected 12+ months of data\"\n    points += 5\n    feedback.append(f\"✓ Date is datetime type, {len(rates_df)} months of data\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Date/size check failed: {type(e).__name__}\")\n\ntry:\n    # Check analysis_text has substantive content\n    assert 'analysis_text' in globals(), \"analysis_text variable not defined\"\n    text_length = len(analysis_text.strip())\n    assert text_length > 200, f\"Analysis too short ({text_length} chars) - need 5-8 meaningful sentences\"\n    assert \"YOUR ANALYSIS HERE\" not in analysis_text, \"Replace placeholder text with your analysis\"\n    assert \"YOUR ANSWER HERE\" not in analysis_text, \"Replace placeholder text with your analysis\"\n    points += 5\n    feedback.append(f\"✓ Analysis text provided ({text_length} characters)\")\nexcept AssertionError as e:\n    feedback.append(f\"✗ {e}\")\nexcept Exception as e:\n    feedback.append(f\"✗ Analysis text check failed: {type(e).__name__}\")\n\nrecord_score('Task 5', points, 20, feedback)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-results",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN: WRITE RESULTS ===\nimport json\nimport datetime\n\nresult = {\n    'scores': __assessment_scores,\n    'feedback': __assessment_feedback,\n    'timestamp': datetime.datetime.now().isoformat()\n}\n\nwith open('assessment_result.json', 'w') as f:\n    json.dump(result, f, indent=2)\n\nprint(\"Assessment Results:\")\ntotal = sum(s[0] for s in __assessment_scores.values())\nmax_total = sum(s[1] for s in __assessment_scores.values())\nfor task, (pts, max_pts) in __assessment_scores.items():\n    print(f\"  {task}: {pts}/{max_pts}\")\n    if task in __assessment_feedback:\n        for fb in __assessment_feedback[task]:\n            print(f\"    {fb}\")\nprint(f\"\\nTotal: {total}/{max_total}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}