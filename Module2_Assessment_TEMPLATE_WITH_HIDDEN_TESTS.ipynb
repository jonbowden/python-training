{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcfef08",
   "metadata": {},
   "source": [
    "# Module 2 – Python for Data Work Assessment (Instructor Version)\n",
    "\n",
    "⚠️ **Instructor / Grading Template**\n",
    "\n",
    "This notebook contains **hidden assessment logic** and must NOT be shared with students.\n",
    "\n",
    "Purpose:\n",
    "- Inject student code programmatically\n",
    "- Run automated tests\n",
    "- Produce authoritative scores\n",
    "\n",
    "**Total Points:** 100 (20 points per task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740cd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN: SCORING SETUP ===\n",
    "__assessment_scores = {}\n",
    "\n",
    "def record_score(exercise, points, max_points):\n",
    "    __assessment_scores[exercise] = (points, max_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN: IMPORTS FOR TESTING ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 10)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task1-header",
   "metadata": {},
   "source": [
    "## Task 1 — Load & Inspect DJIA (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task1-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN TEST: Task 1 ===\n",
    "points = 0\n",
    "try:\n",
    "    # Check djia_df exists\n",
    "    assert 'djia_df' in globals() or 'djia_df' in dir(), \"djia_df not defined\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check required columns\n",
    "    required_cols = {'Date', 'Open', 'High', 'Low', 'Close', 'Volume'}\n",
    "    assert required_cols.issubset(set(djia_df.columns)), \"Missing required columns\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check data is sorted by date\n",
    "    dates = pd.to_datetime(djia_df['Date'])\n",
    "    assert dates.is_monotonic_increasing, \"Data not sorted by date\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check Date is datetime type\n",
    "    assert pd.api.types.is_datetime64_any_dtype(djia_df['Date']), \"Date not datetime type\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "record_score('Task 1', points, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task2-header",
   "metadata": {},
   "source": [
    "## Task 2 — Cleaning & Feature Engineering (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task2-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN TEST: Task 2 ===\n",
    "points = 0\n",
    "try:\n",
    "    # Check Date is datetime\n",
    "    assert pd.api.types.is_datetime64_any_dtype(djia_df['Date']), \"Date not datetime\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check Daily_Return column exists\n",
    "    assert 'Daily_Return' in djia_df.columns, \"Daily_Return column missing\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check Daily_Return has values (not all NaN)\n",
    "    assert djia_df['Daily_Return'].notna().sum() > 200, \"Daily_Return mostly empty\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check Daily_Return is reasonable (percentage values)\n",
    "    assert djia_df['Daily_Return'].abs().mean() < 10, \"Daily_Return values unreasonable\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "record_score('Task 2', points, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task3-header",
   "metadata": {},
   "source": [
    "## Task 3 — Visual Analysis (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task3-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN TEST: Task 3 ===\n",
    "# Visual tasks are harder to automate - award points for having the data ready\n",
    "points = 0\n",
    "try:\n",
    "    # Check djia_df exists with Close column for plotting\n",
    "    assert 'djia_df' in globals()\n",
    "    assert 'Close' in djia_df.columns\n",
    "    assert len(djia_df) > 0\n",
    "    points += 10\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check Daily_Return exists for histogram\n",
    "    assert 'Daily_Return' in djia_df.columns\n",
    "    assert djia_df['Daily_Return'].notna().sum() > 0\n",
    "    points += 10\n",
    "except:\n",
    "    pass\n",
    "\n",
    "record_score('Task 3', points, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task4-header",
   "metadata": {},
   "source": [
    "## Task 4 — Multi-Dataset Analysis (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task4-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN TEST: Task 4 ===\n",
    "points = 0\n",
    "try:\n",
    "    # Check fx_df exists\n",
    "    assert 'fx_df' in globals(), \"fx_df not defined\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check required columns\n",
    "    assert {'Date', 'USD_GBP', 'FX_Return'}.issubset(set(fx_df.columns)), \"Missing columns\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check FX_Return is reasonable\n",
    "    assert fx_df['FX_Return'].abs().mean() < 5, \"FX_Return values unreasonable\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check Date is datetime\n",
    "    assert pd.api.types.is_datetime64_any_dtype(fx_df['Date']), \"Date not datetime\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "record_score('Task 4', points, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task5-header",
   "metadata": {},
   "source": [
    "## Task 5 — Macro Insight (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task5-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN TEST: Task 5 ===\n",
    "points = 0\n",
    "try:\n",
    "    # Check rates_df exists\n",
    "    assert 'rates_df' in globals(), \"rates_df not defined\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check FEDFUNDS column\n",
    "    assert 'FEDFUNDS' in rates_df.columns, \"FEDFUNDS column missing\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check Date is datetime\n",
    "    assert pd.api.types.is_datetime64_any_dtype(rates_df['Date']), \"Date not datetime\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check analysis_text has content\n",
    "    assert 'analysis_text' in globals(), \"analysis_text not defined\"\n",
    "    assert len(analysis_text.strip()) > 100, \"Analysis too short\"\n",
    "    points += 5\n",
    "except:\n",
    "    pass\n",
    "\n",
    "record_score('Task 5', points, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN: WRITE RESULTS ===\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "result = {\n",
    "    'scores': __assessment_scores,\n",
    "    'timestamp': datetime.datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open('assessment_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(\"Assessment Results:\")\n",
    "total = sum(s[0] for s in __assessment_scores.values())\n",
    "max_total = sum(s[1] for s in __assessment_scores.values())\n",
    "for task, (pts, max_pts) in __assessment_scores.items():\n",
    "    print(f\"  {task}: {pts}/{max_pts}\")\n",
    "print(f\"\\nTotal: {total}/{max_total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
