{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcfef08",
   "metadata": {},
   "source": "# Module 2 – Python for Data Work Assessment (Instructor Version)\n\n**Instructor / Grading Template**\n\nThis notebook contains **hidden assessment logic** and must NOT be shared with students.\n\nPurpose:\n- Inject student code programmatically\n- Run automated tests\n- Produce authoritative scores\n\n**Assessment Data Sources:**\nStudents must download real data from:\n1. DJIA from WSJ or Yahoo Finance -> `djia_data.csv`\n2. USD/GBP from FRED (DEXUSUK) -> `fx_usd_gbp.csv`  \n3. Federal Funds Rate from FRED (FEDFUNDS) -> `fed_funds_rate.csv`\n\n**Total Points:** 100 (20 points per task)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740cd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN: SCORING SETUP ===\n",
    "__assessment_scores = {}\n",
    "\n",
    "def record_score(exercise, points, max_points):\n",
    "    __assessment_scores[exercise] = (points, max_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN: IMPORTS FOR TESTING ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 10)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task1-header",
   "metadata": {},
   "source": [
    "## Task 1 — Load & Inspect DJIA (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task1-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 1 ===\n# Tests loading REAL DJIA data from djia_data.csv\npoints = 0\ntry:\n    # Check djia_df exists\n    assert 'djia_df' in globals() or 'djia_df' in dir(), \"djia_df not defined\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check required columns (case-insensitive check, then verify exact names)\n    required_cols = {'Date', 'Open', 'High', 'Low', 'Close', 'Volume'}\n    actual_cols = set(djia_df.columns)\n    assert required_cols.issubset(actual_cols), f\"Missing required columns. Have: {actual_cols}\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check data is sorted by date (oldest first)\n    dates = pd.to_datetime(djia_df['Date'])\n    assert dates.is_monotonic_increasing, \"Data not sorted by date (oldest first)\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check Date is datetime type and data has reasonable size (real data should have 200+ rows for a year)\n    assert pd.api.types.is_datetime64_any_dtype(djia_df['Date']), \"Date not datetime type\"\n    assert len(djia_df) >= 100, f\"Data seems too small ({len(djia_df)} rows) - did you load the full CSV?\"\n    points += 5\nexcept:\n    pass\n\nrecord_score('Task 1', points, 20)"
  },
  {
   "cell_type": "markdown",
   "id": "task2-header",
   "metadata": {},
   "source": [
    "## Task 2 — Cleaning & Feature Engineering (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task2-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 2 ===\n# Tests cleaning and feature engineering on real DJIA data\npoints = 0\ntry:\n    # Check Date is datetime\n    assert pd.api.types.is_datetime64_any_dtype(djia_df['Date']), \"Date not datetime\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check Daily_Return column exists\n    assert 'Daily_Return' in djia_df.columns, \"Daily_Return column missing\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check Daily_Return has values (first row will be NaN from pct_change, rest should have data)\n    non_null_count = djia_df['Daily_Return'].notna().sum()\n    assert non_null_count >= len(djia_df) - 5, f\"Daily_Return has too many NaN values ({non_null_count} valid)\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check Daily_Return is reasonable for real stock data (typically -5% to +5% daily)\n    mean_abs_return = djia_df['Daily_Return'].abs().mean()\n    assert 0.01 < mean_abs_return < 5, f\"Daily_Return mean={mean_abs_return} seems unreasonable for real data\"\n    points += 5\nexcept:\n    pass\n\nrecord_score('Task 2', points, 20)"
  },
  {
   "cell_type": "markdown",
   "id": "task3-header",
   "metadata": {},
   "source": [
    "## Task 3 — Visual Analysis (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task3-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN TEST: Task 3 ===\n",
    "# Visual tasks are harder to automate - award points for having the data ready\n",
    "points = 0\n",
    "try:\n",
    "    # Check djia_df exists with Close column for plotting\n",
    "    assert 'djia_df' in globals()\n",
    "    assert 'Close' in djia_df.columns\n",
    "    assert len(djia_df) > 0\n",
    "    points += 10\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Check Daily_Return exists for histogram\n",
    "    assert 'Daily_Return' in djia_df.columns\n",
    "    assert djia_df['Daily_Return'].notna().sum() > 0\n",
    "    points += 10\n",
    "except:\n",
    "    pass\n",
    "\n",
    "record_score('Task 3', points, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task4-header",
   "metadata": {},
   "source": [
    "## Task 4 — Multi-Dataset Analysis (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task4-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 4 ===\n# Tests loading REAL FX data from FRED (fx_usd_gbp.csv)\npoints = 0\ntry:\n    # Check fx_df exists\n    assert 'fx_df' in globals(), \"fx_df not defined\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check required columns\n    assert {'Date', 'USD_GBP', 'FX_Return'}.issubset(set(fx_df.columns)), \"Missing columns (need Date, USD_GBP, FX_Return)\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check USD_GBP values are in reasonable range for real FX data (USD/GBP typically 1.1-1.5)\n    mean_rate = fx_df['USD_GBP'].mean()\n    assert 1.0 < mean_rate < 1.6, f\"USD_GBP mean={mean_rate} seems unreasonable for real FX data\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check Date is datetime and data has reasonable size\n    assert pd.api.types.is_datetime64_any_dtype(fx_df['Date']), \"Date not datetime\"\n    assert len(fx_df) >= 50, f\"Data seems too small ({len(fx_df)} rows) - did you load the full CSV?\"\n    points += 5\nexcept:\n    pass\n\nrecord_score('Task 4', points, 20)"
  },
  {
   "cell_type": "markdown",
   "id": "task5-header",
   "metadata": {},
   "source": [
    "## Task 5 — Macro Insight (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task5-test",
   "metadata": {},
   "outputs": [],
   "source": "# === HIDDEN TEST: Task 5 ===\n# Tests loading REAL Fed Funds Rate data from FRED (fed_funds_rate.csv)\npoints = 0\ntry:\n    # Check rates_df exists\n    assert 'rates_df' in globals(), \"rates_df not defined\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check FEDFUNDS column exists\n    assert 'FEDFUNDS' in rates_df.columns, \"FEDFUNDS column missing\"\n    # Check values are in reasonable range (0-10% historically)\n    max_rate = rates_df['FEDFUNDS'].max()\n    assert 0 < max_rate < 10, f\"FEDFUNDS max={max_rate} seems unreasonable\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check Date is datetime\n    assert pd.api.types.is_datetime64_any_dtype(rates_df['Date']), \"Date not datetime\"\n    # Check we have multi-year data (should have 40+ months for 2020-2024)\n    assert len(rates_df) >= 12, f\"Data seems too small ({len(rates_df)} rows) - need at least 1 year\"\n    points += 5\nexcept:\n    pass\n\ntry:\n    # Check analysis_text has substantive content\n    assert 'analysis_text' in globals(), \"analysis_text not defined\"\n    # Must have real analysis (more than placeholder text)\n    assert len(analysis_text.strip()) > 200, \"Analysis too short - need 5-8 meaningful sentences\"\n    # Check it doesn't still contain placeholder text\n    assert \"YOUR ANALYSIS HERE\" not in analysis_text, \"Replace placeholder text with your analysis\"\n    points += 5\nexcept:\n    pass\n\nrecord_score('Task 5', points, 20)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIDDEN: WRITE RESULTS ===\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "result = {\n",
    "    'scores': __assessment_scores,\n",
    "    'timestamp': datetime.datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open('assessment_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(\"Assessment Results:\")\n",
    "total = sum(s[0] for s in __assessment_scores.values())\n",
    "max_total = sum(s[1] for s in __assessment_scores.values())\n",
    "for task, (pts, max_pts) in __assessment_scores.items():\n",
    "    print(f\"  {task}: {pts}/{max_pts}\")\n",
    "print(f\"\\nTotal: {total}/{max_total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}