{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Module 3 - LLM Fundamentals Assessment\n",
    "\n",
    "**Total Points: 20**\n",
    "\n",
    "## Assessment Instructions\n",
    "\n",
    "1. Complete all exercises in this notebook\n",
    "2. Do NOT rename any functions - the grader expects specific names\n",
    "3. Ensure your notebook runs without errors before submission\n",
    "4. You may use either local Ollama or the remote CodeVision LLM API\n",
    "\n",
    "## LLM Setup\n",
    "\n",
    "Configure your LLM endpoint below. The exercises will use this configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIGURATION =====\n",
    "# Option A: Local Ollama (default)\n",
    "LLM_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Option B: Remote CodeVision LLM API (uncomment and set if using)\n",
    "# LLM_BASE_URL = \"https://your-codevision-endpoint\"\n",
    "\n",
    "DEFAULT_MODEL = \"phi3:mini\"\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1 - Basic LLM Caller (4 points)\n",
    "\n",
    "Create a function `call_llm` that:\n",
    "- Takes parameters: `prompt` (str), `temperature` (float, default 0.0)\n",
    "- Calls the `/api/generate` endpoint with the configured `LLM_BASE_URL`\n",
    "- Sends a JSON payload with keys: `model`, `prompt`, `temperature`, `stream` (set to False)\n",
    "- Returns the parsed JSON response as a dictionary\n",
    "\n",
    "**Requirements:**\n",
    "- Use `requests.post()` to make the HTTP call\n",
    "- Use `DEFAULT_MODEL` for the model name\n",
    "- Handle the response with `.json()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Implement call_llm function\n",
    "\n",
    "def call_llm(prompt: str, temperature: float = 0.0) -> dict:\n",
    "    \"\"\"Call an LLM endpoint and return the response.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test your function (optional)\n",
    "# result = call_llm(\"Say hello in one word.\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2 - Extract Response Text (3 points)\n",
    "\n",
    "Create a function `get_response_text` that:\n",
    "- Takes `prompt` (str) as input\n",
    "- Calls `call_llm` with temperature=0.0\n",
    "- Extracts and returns ONLY the text from the `\"response\"` key\n",
    "- Returns an empty string if the key doesn't exist\n",
    "\n",
    "**Requirements:**\n",
    "- Must use your `call_llm` function\n",
    "- Use `.get()` for safe dictionary access\n",
    "- Return type must be `str`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Implement get_response_text function\n",
    "\n",
    "def get_response_text(prompt: str) -> str:\n",
    "    \"\"\"Call LLM and return just the response text.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test your function (optional)\n",
    "# text = get_response_text(\"What is 2+2? Answer with just the number.\")\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3 - JSON Output Parser (4 points)\n",
    "\n",
    "Create a function `parse_json_response` that:\n",
    "- Takes `prompt` (str) as input\n",
    "- Calls `get_response_text` to get the LLM output\n",
    "- Attempts to parse the response as JSON\n",
    "- Returns a tuple: `(success: bool, result: dict or str)`\n",
    "  - If parsing succeeds: `(True, parsed_dict)`\n",
    "  - If parsing fails: `(False, error_message)`\n",
    "\n",
    "**Requirements:**\n",
    "- Use `json.loads()` for parsing\n",
    "- Use try/except to handle `json.JSONDecodeError`\n",
    "- The error message should describe the failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Implement parse_json_response function\n",
    "\n",
    "def parse_json_response(prompt: str) -> tuple:\n",
    "    \"\"\"Call LLM, attempt to parse response as JSON, return (success, result).\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test your function (optional)\n",
    "# success, result = parse_json_response('Return ONLY valid JSON: {\"test\": 123}')\n",
    "# print(f\"Success: {success}, Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 4 - Temperature Comparison (4 points)\n",
    "\n",
    "Create a function `compare_temperatures` that:\n",
    "- Takes `prompt` (str) as input\n",
    "- Calls `call_llm` twice with the SAME prompt:\n",
    "  - Once with temperature=0.0\n",
    "  - Once with temperature=0.8\n",
    "- Returns a dictionary with keys:\n",
    "  - `\"low_temp\"`: response text from temperature=0.0\n",
    "  - `\"high_temp\"`: response text from temperature=0.8\n",
    "  - `\"are_identical\"`: boolean indicating if both responses are exactly the same\n",
    "\n",
    "**Requirements:**\n",
    "- Use your `call_llm` function\n",
    "- Extract response text using the `\"response\"` key\n",
    "- Compare strings exactly for `are_identical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex4-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Implement compare_temperatures function\n",
    "\n",
    "def compare_temperatures(prompt: str) -> dict:\n",
    "    \"\"\"Compare LLM responses at different temperatures.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test your function (optional)\n",
    "# result = compare_temperatures(\"List 3 fruits.\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 5 - Structured Prompt Builder (5 points)\n",
    "\n",
    "Create a function `build_structured_prompt` that:\n",
    "- Takes parameters:\n",
    "  - `system_instruction` (str): behavior rules for the LLM\n",
    "  - `task` (str): what the LLM should do\n",
    "  - `constraints` (list of str): output constraints\n",
    "- Returns a formatted prompt string with clearly labeled sections:\n",
    "  ```\n",
    "  SYSTEM:\n",
    "  {system_instruction}\n",
    "  \n",
    "  TASK:\n",
    "  {task}\n",
    "  \n",
    "  CONSTRAINTS:\n",
    "  - {constraint1}\n",
    "  - {constraint2}\n",
    "  ```\n",
    "\n",
    "**Requirements:**\n",
    "- Each constraint should be on its own line, prefixed with `\"- \"`\n",
    "- Sections must be separated by blank lines\n",
    "- Use uppercase labels: SYSTEM, TASK, CONSTRAINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex5-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Implement build_structured_prompt function\n",
    "\n",
    "def build_structured_prompt(system_instruction: str, task: str, constraints: list) -> str:\n",
    "    \"\"\"Build a structured prompt with system, task, and constraints.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test your function (optional)\n",
    "# prompt = build_structured_prompt(\n",
    "#     \"You are a helpful assistant.\",\n",
    "#     \"Explain Python lists.\",\n",
    "#     [\"Use simple language\", \"Maximum 2 sentences\"]\n",
    "# )\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "submission",
   "metadata": {},
   "source": [
    "---\n",
    "## Submission\n",
    "\n",
    "Before submitting:\n",
    "1. **Restart kernel** and **Run All Cells** to ensure everything works\n",
    "2. Verify all functions are defined and return correct types\n",
    "3. Save the notebook\n",
    "\n",
    "Submit your completed notebook via the [Module 3 Assessment Form](https://forms.google.com/MODULE3_FORM_LINK)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
