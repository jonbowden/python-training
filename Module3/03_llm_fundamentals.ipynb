{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2394ad",
   "metadata": {},
   "source": [
    "# Module 3 — LLM Fundamentals (CodeVision Academy)\n",
    "\n",
    "## Overview\n",
    "This module introduces **Large Language Models (LLMs)** from an engineering and enterprise perspective.\n",
    "It is **code-first**, grounded in Python, and builds directly on:\n",
    "\n",
    "- **Module 1:** Python fundamentals (functions, JSON, notebooks)\n",
    "- **Module 2:** Data work with Pandas and visualisation\n",
    "\n",
    "You will learn how LLMs work, how to call them from Python, how they fail, and how to use them safely in regulated environments such as banking and financial services.\n",
    "\n",
    "### Supported LLM access methods (choose one)\n",
    "- **Local laptop LLM** — run a lightweight model using **Ollama** on your PC.\n",
    "- **Remote CodeVision LLM API** — an Ollama-compatible `/api/generate` endpoint provided by the course admin.\n",
    "\n",
    "Both options use the same request shape. Your code should work by changing **one** base URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6cbd51",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. Explain what an LLM is (and what it is not)\n",
    "2. Explain tokens, context windows, and training vs inference\n",
    "3. Call an LLM from Python via HTTP API (local or remote)\n",
    "4. Control determinism using temperature\n",
    "5. Force structured output (JSON) and validate it\n",
    "6. Recognise hallucinations and common failure modes\n",
    "7. Apply LLMs safely in a small data pipeline\n",
    "8. Explain why LLMs alone are insufficient for enterprise use, and why grounding (RAG) helps (Module 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d09d9",
   "metadata": {},
   "source": [
    "## Setup — choose your endpoint\n",
    "\n",
    "### Option A — Local laptop LLM (Ollama)\n",
    "1. Install Ollama: https://ollama.com/download  \n",
    "2. Pull models:\n",
    "   - `ollama pull phi3:mini` (mandatory for this module)\n",
    "   - `ollama pull llama3.2:1b` (optional comparison)\n",
    "3. Ensure Ollama is running (it often starts automatically)\n",
    "\n",
    "Local API:\n",
    "- Base URL: `http://localhost:11434`\n",
    "- Endpoint: `/api/generate`\n",
    "\n",
    "### Option B — Remote CodeVision LLM API\n",
    "- Base URL: provided by course admin\n",
    "- Endpoint is compatible with Ollama’s `/api/generate`\n",
    "\n",
    "Set `LLM_BASE_URL` below to match your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85339729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIG (edit only LLM_BASE_URL if needed) =====\n",
    "LLM_BASE_URL = \"http://localhost:11434\"   # Local laptop Ollama\n",
    "# LLM_BASE_URL = \"https://YOUR-REMOTE-ENDPOINT\"  # Remote CodeVision LLM API\n",
    "\n",
    "DEFAULT_MODEL = \"phi3:mini\"      # mandatory\n",
    "# DEFAULT_MODEL = \"llama3.2:1b\"  # optional comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5baf971",
   "metadata": {},
   "source": [
    "## Common helper: a robust LLM caller\n",
    "\n",
    "We will reuse this helper in multiple sections. It:\n",
    "- calls `/api/generate`\n",
    "- passes `model`, `prompt`, `temperature`, `stream`\n",
    "- returns parsed JSON\n",
    "\n",
    "If your endpoint is down, you will get an HTTP error. That is normal and should be handled in production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a3479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def call_llm(prompt: str, model: str = DEFAULT_MODEL, temperature: float = 0.0, stream: bool = False, timeout_s: int = 60) -> dict:\n",
    "    \"\"\"Call an Ollama-compatible /api/generate endpoint and return parsed JSON.\"\"\"\n",
    "    url = f\"{LLM_BASE_URL.rstrip('/')}/api/generate\"\n",
    "    payload = {\"model\": model, \"prompt\": prompt, \"temperature\": temperature, \"stream\": stream}\n",
    "    r = requests.post(url, json=payload, timeout=timeout_s)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "# Smoke test\n",
    "out = call_llm(\"In one sentence, define inflation for a banking audience.\", temperature=0.0)\n",
    "print(out.get(\"response\", \"\")[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686c57a",
   "metadata": {},
   "source": [
    "# Section 3.1 — What is a Large Language Model?\n",
    "\n",
    "An LLM is best understood as a **next-token prediction engine**. It generates text that is statistically likely, not text that is guaranteed true.\n",
    "\n",
    "**Enterprise mindset:** treat LLM output as **untrusted** unless validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Complete: 'Interest rates are rising because'\"\n",
    "print(call_llm(prompt, temperature=0.7).get(\"response\",\"\")[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506f33ba",
   "metadata": {},
   "source": [
    "# Section 3.2 — Tokens: How LLMs see text\n",
    "\n",
    "LLMs operate on **tokens** (subword pieces), not words. Tokenisation affects context limits and truncation.\n",
    "\n",
    "Practical implication: keep prompts concise and plan for chunking on long documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c6027",
   "metadata": {},
   "source": [
    "# Section 3.3 — Training vs inference\n",
    "\n",
    "- **Training**: offline learning of model parameters from huge datasets.\n",
    "- **Inference**: runtime generation when you call the model endpoint.\n",
    "\n",
    "This module focuses on inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfc117",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = call_llm(\"Explain training vs inference in 2 bullet points.\", temperature=0.0)\n",
    "print(resp[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00392b1f",
   "metadata": {},
   "source": [
    "# Section 3.4 — LLMs as services (APIs)\n",
    "\n",
    "Treat the LLM like any other service: send JSON request, receive JSON response. This builds on your JSON and requests skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = call_llm(\"Say hello.\")\n",
    "print(resp.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d183d",
   "metadata": {},
   "source": [
    "# Section 3.5 — Prompt structure: role, task, constraints\n",
    "\n",
    "With single-prompt endpoints, simulate roles by placing behaviour rules first, task second, constraints last.\n",
    "\n",
    "This reduces ambiguity and improves reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9618040",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are a cautious banking analyst. Do not speculate. If unsure, say 'Insufficient information'.\"\n",
    "task = \"Summarise for an executive: FX volatility increased due to rate differentials.\"\n",
    "constraints = \"Return exactly 2 bullet points. Max 20 words each.\"\n",
    "prompt = f\"SYSTEM:\\n{system}\\n\\nTASK:\\n{task}\\n\\nCONSTRAINTS:\\n{constraints}\"\n",
    "print(call_llm(prompt, temperature=0.0)[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c588100",
   "metadata": {},
   "source": [
    "# Section 3.6 — Temperature and determinism\n",
    "\n",
    "Temperature controls randomness. Low temperature (0.0–0.2) is preferred in regulated workflows for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcae6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain what a context window is in 2 sentences.\"\n",
    "low = call_llm(prompt, temperature=0.0)[\"response\"]\n",
    "high = call_llm(prompt, temperature=0.8)[\"response\"]\n",
    "print(\"Temp 0.0:\\n\", low)\n",
    "print(\"\\nTemp 0.8:\\n\", high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b8460",
   "metadata": {},
   "source": [
    "# Section 3.7 — Hallucinations (confident but wrong)\n",
    "\n",
    "Hallucinations occur because the model optimises for plausible text rather than verified truth. Never treat confident language as evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1405bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What was the DJIA close on 32 December 2024? Answer with a number.\"\n",
    "print(call_llm(prompt, temperature=0.0)[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e20418",
   "metadata": {},
   "source": [
    "# Section 3.8 — Context windows: why long inputs fail\n",
    "\n",
    "LLMs have a maximum context window. Long inputs can be truncated, producing generic or incomplete summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = (\"This is a paragraph from a long banking policy document. \" * 1500)\n",
    "prompt = f\"Summarise in 3 bullets:\\n{long_text}\"\n",
    "print(call_llm(prompt, temperature=0.0)[\"response\"][:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4a3ff",
   "metadata": {},
   "source": [
    "# Section 3.9 — Prompt hygiene: common mistakes and fixes\n",
    "\n",
    "Avoid vague asks, missing constraints, and multi-task prompts. Prefer clear audience, format, and uncertainty policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8704b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = \"Tell me about interest rates.\"\n",
    "good = \"Explain interest rates to a new bank analyst in 3 bullets, <= 18 words each. No speculation.\"\n",
    "print(\"BAD:\\n\", call_llm(bad, temperature=0.0)[\"response\"])\n",
    "print(\"\\nGOOD:\\n\", call_llm(good, temperature=0.0)[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190194c",
   "metadata": {},
   "source": [
    "# Section 3.10 — Structured output: why JSON matters\n",
    "\n",
    "JSON output enables deterministic parsing, validation, and automation. This builds directly on Module 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "prompt = (\n",
    "\"Return ONLY valid JSON with keys: summary (string), risks (array of exactly 3 strings). \"\n",
    "\"No extra text. Use double quotes. \"\n",
    "\"Text: Banks face credit risk, market risk, and operational risk.\"\n",
    ")\n",
    "raw = call_llm(prompt, temperature=0.0)[\"response\"]\n",
    "print(raw)\n",
    "data = json.loads(raw)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d31e8",
   "metadata": {},
   "source": [
    "# Section 3.11 — Defensive parsing and validation\n",
    "\n",
    "Models sometimes return invalid JSON. Handle this safely: parse, validate, retry or fail clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0691996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def safe_json_loads(s: str):\n",
    "    try:\n",
    "        return True, json.loads(s)\n",
    "    except Exception as e:\n",
    "        return False, f\"{type(e).__name__}: {e}\"\n",
    "raw = call_llm('Return JSON only: {\"a\": 1}', temperature=0.0)[\"response\"]\n",
    "ok, parsed = safe_json_loads(raw)\n",
    "print(\"OK?\", ok)\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962a733",
   "metadata": {},
   "source": [
    "# Section 3.12 — Text validators: length, bullets, vocabulary\n",
    "\n",
    "Not all tasks need JSON. You can validate text using deterministic rules like bullet count and max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c894671",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = call_llm(\"Return exactly 3 bullet points about liquidity risk.\", temperature=0.0)[\"response\"]\n",
    "bullets = [ln for ln in text.splitlines() if ln.strip().startswith((\"-\", \"*\"))]\n",
    "print(\"Bullet count:\", len(bullets))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39bd7b",
   "metadata": {},
   "source": [
    "# Section 3.13 — LLMs inside a Pandas pipeline\n",
    "\n",
    "LLMs can augment data pipelines by generating summaries or tags. Start small and validate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"id\": [1,2,3],\n",
    "    \"text\": [\n",
    "        \"Credit risk is the possibility of loss from borrower default.\",\n",
    "        \"Market risk comes from adverse movements in interest rates and FX.\",\n",
    "        \"Operational risk arises from process, people, or system failures.\"\n",
    "    ]\n",
    "})\n",
    "def summarise_row(t: str) -> str:\n",
    "    prompt = f\"Summarise in 10 words or fewer: {t}\"\n",
    "    return call_llm(prompt, temperature=0.0)[\"response\"].strip()\n",
    "df[\"summary\"] = df[\"text\"].apply(summarise_row)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52307074",
   "metadata": {},
   "source": [
    "# Section 3.14 — Cost/latency mindset: caching\n",
    "\n",
    "LLM calls are slow compared to normal functions. Use caching for repeated prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e67697",
   "metadata": {},
   "outputs": [],
   "source": [
    "_cache = {}\n",
    "def cached_llm(prompt: str, temperature: float = 0.0) -> str:\n",
    "    key = (prompt, temperature, DEFAULT_MODEL, LLM_BASE_URL)\n",
    "    if key in _cache:\n",
    "        return _cache[key]\n",
    "    out = call_llm(prompt, temperature=temperature)[\"response\"].strip()\n",
    "    _cache[key] = out\n",
    "    return out\n",
    "p = \"Summarise: Banks face credit and market risk.\"\n",
    "print(cached_llm(p, 0.0))\n",
    "print(cached_llm(p, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20793697",
   "metadata": {},
   "source": [
    "# Section 3.15 — Local vs remote endpoint trade-offs\n",
    "\n",
    "Local: simple, private, predictable. Remote: centrally managed, potentially faster, requires network/access control. Your code should work for both by switching LLM_BASE_URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17109616",
   "metadata": {},
   "source": [
    "# Section 3.16 — Enterprise constraints: auditability and compliance\n",
    "\n",
    "Log prompts (or hashes), parameters, model, and output metadata for auditability. Avoid sending sensitive data to unapproved endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4459bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib, time\n",
    "def audit_meta(prompt: str, response_text: str, model: str, temperature: float) -> dict:\n",
    "    return {\n",
    "        \"ts\": time.time(),\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"prompt_sha256\": hashlib.sha256(prompt.encode()).hexdigest(),\n",
    "        \"response_sha256\": hashlib.sha256(response_text.encode()).hexdigest(),\n",
    "        \"response_len\": len(response_text),\n",
    "    }\n",
    "p = \"Summarise operational risk in 12 words.\"\n",
    "resp = call_llm(p, temperature=0.0)\n",
    "meta = audit_meta(p, resp.get(\"response\",\"\"), resp.get(\"model\", DEFAULT_MODEL), 0.0)\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588d412",
   "metadata": {},
   "source": [
    "# Section 3.17 — Evaluation without using another LLM\n",
    "\n",
    "Prefer deterministic checks: schema validation, key checks, length constraints, bullet counts. Avoid 'LLM judging LLM' as your only control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362b0ee",
   "metadata": {},
   "source": [
    "# Section 3.18 — Safety patterns: uncertainty and fallbacks\n",
    "\n",
    "Include an uncertainty policy: if unsure, say 'Insufficient information'. Build fallbacks when validation fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b401c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"If you are unsure, respond exactly: Insufficient information. Do not guess.\"\n",
    "task = \"What is the exact USD/GBP rate at 09:31 UTC yesterday?\"\n",
    "prompt = f\"{system}\\n\\n{task}\"\n",
    "print(call_llm(prompt, temperature=0.0)[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb7962",
   "metadata": {},
   "source": [
    "# Section 3.19 — Why LLMs alone are not enough\n",
    "\n",
    "LLMs have hallucinations, context limits, and no grounding in your internal data by default. This motivates grounding and retrieval techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db0ee7",
   "metadata": {},
   "source": [
    "# Section 3.20 — Preparing for Module 4 (Grounding / RAG)\n",
    "\n",
    "Mental model: LLM = language engine; RAG = evidence + memory. RAG reduces hallucinations by supplying trusted context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc72488",
   "metadata": {},
   "source": [
    "## Practice exercises (ungraded)\n",
    "1. Force JSON output for a classification task and parse it.\n",
    "2. Demonstrate one hallucination and explain why it happened.\n",
    "3. Enrich a small DataFrame with LLM-generated summaries and add a cache.\n",
    "4. Add a validator enforcing: exactly 3 bullets and <= 20 words each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e69a1",
   "metadata": {},
   "source": [
    "## Module summary\n",
    "- LLMs generate **probabilistic text**, not guaranteed truth.\n",
    "- Treat outputs as **untrusted** unless validated.\n",
    "- Use **low temperature** for consistency and auditability.\n",
    "- Prefer **structured outputs (JSON)** for automation.\n",
    "- Design for **failures, retries, and fallbacks**."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}