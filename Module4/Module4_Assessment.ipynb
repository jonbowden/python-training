{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d458d54",
   "metadata": {},
   "source": [
    "# Module 4 Assessment — ML & DL Foundations (Student Version)\n",
    "\n",
    "**No human grading.** This assessment is graded automatically using deterministic checks.\n",
    "\n",
    "## How this connects to Module 3 and upcoming RAG\n",
    "- **Module 3** taught you how to call LLMs safely and why hallucinations happen.\n",
    "- **Module 4** explains the ML/DL training dynamics that make hallucinations and instability expected.\n",
    "- **Upcoming RAG modules** show how to ground LLM outputs with evidence.\n",
    "\n",
    "## What we grade\n",
    "We grade:\n",
    "- Presence of required concepts (keyword groups)\n",
    "- Minimum depth (length requirements)\n",
    "- Clear linkage to enterprise implications (banking / governance)\n",
    "\n",
    "## Instructions\n",
    "- Fill in the text fields below with full sentences.\n",
    "- Use **6–10 sentences** unless stated otherwise.\n",
    "- Do **not** rename variable names.\n",
    "- Avoid bullet-only answers; write proper explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3237a7",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1 — Concept mapping (20 points)\n",
    "\n",
    "**Prompt:** Explain the relationship between **AI**, **ML**, **DL**, and **LLMs**.\n",
    "\n",
    "Include:\n",
    "- the subset chain (AI → ML → DL)\n",
    "- where LLMs sit (DL + GenAI)\n",
    "- one sentence on why this matters in enterprise settings\n",
    "\n",
    "Write **5–8 sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_mapping = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872910f2",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2 — Model anatomy (20 points)\n",
    "\n",
    "**Prompt:** Explain the anatomy of a neural network.\n",
    "\n",
    "Include:\n",
    "- neurons/nodes\n",
    "- weights\n",
    "- biases\n",
    "- activation functions (mention ReLU or sigmoid)\n",
    "- layers (input/hidden/output)\n",
    "\n",
    "Write **6–10 sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_anatomy = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5df768",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3 — How learning works (20 points)\n",
    "\n",
    "**Prompt:** Explain how a neural network learns during training.\n",
    "\n",
    "Include:\n",
    "- loss function (error signal)\n",
    "- gradient descent (minimising loss)\n",
    "- backpropagation (error flowing backward)\n",
    "- learning rate (step size; too large instability)\n",
    "- convergence (what it means and what it doesn’t)\n",
    "\n",
    "Write **7–12 sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_mechanics = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b215a780",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4 — Overfitting vs underfitting (20 points)\n",
    "\n",
    "**Prompt:** Explain the difference between overfitting and underfitting, and give mitigations.\n",
    "\n",
    "Include:\n",
    "- what overfitting looks like (training vs validation behaviour)\n",
    "- what underfitting looks like\n",
    "- at least one mitigation for each (e.g., regularisation, early stopping, more data, simpler model)\n",
    "- one sentence tying this to risk in financial models\n",
    "\n",
    "Write **7–12 sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef57623",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_analysis = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a400a",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5 — LLM behaviour + grounding (20 points)\n",
    "\n",
    "**Prompt:** Based on your understanding of ML/DL, explain why LLM hallucinations are expected and why grounding (RAG) helps.\n",
    "\n",
    "Include:\n",
    "- hallucination as pattern completion / over-generalisation\n",
    "- connection to training data and next-token prediction\n",
    "- why enterprise settings require evidence and auditability\n",
    "- grounding/retrieval/RAG as mitigation (evidence + context)\n",
    "\n",
    "Write **7–12 sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_grounding_reflection = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122fdd9c",
   "metadata": {},
   "source": "---\n## Submission\n\nSubmit your completed notebook via the [Module 4 Assessment Form](https://docs.google.com/forms/d/e/1FAIpQLSdtHWeARFyjS_Oqs_1H1BM0M1rJtdcfYDaOmejchvkebmWcEQ/viewform).\n\n### Submission Checklist\n- [ ] All variables filled with thoughtful explanations\n- [ ] Answers meet sentence/length guidance\n- [ ] Notebook runs top-to-bottom without errors\n- [ ] Submit this notebook without renaming variables"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}