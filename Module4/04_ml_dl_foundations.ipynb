{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Content\n\nThis notebook prioritizes **intuition over equations** while staying technically correct.\n\nFor every new concept, we explicitly answer:\n\n- **What is this?**\n- **So what? / Why is this important?**\n- **What does this mean in practice?**\n- **Why should I care right now?**\n\n---\n\n## Companion Resources\n- [Hiker's Cheat Sheet (Rosetta Stone)](Module4_Hiker_CheatSheet.md) — Maps the analogy terms to technical terms\n- [Knowledge Checks (5 questions)](Module4_Knowledge_Checks.md) — Test your understanding\n\n> Keep the cheat sheet open while you work. It maps the analogy terms to the technical terms."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 1 — The Big Picture: The Hiker in the Fog (decoded)\n\n## The story\nA hiker is trying to reach the **lowest point** of a landscape, but they can’t see far (fog).  \nThey can only feel the **slope under their feet**, take a step, and see if they’re lower than before.\n\n## Why this story exists (So what?)\nWithout a mental model, ML feels like disconnected jargon.  \nThis story gives you a *single big picture* that every concept fits into.\n\n## The key sentence (memorize this)\n> **Training is the model repeatedly making small changes to itself, keeping the ones that make it less wrong.**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## The Analogy Map (decoded — student-safe)\n\n| In the story | What it really means (plain English) | Why you care |\n|---|---|---|\n| **Hiker** | A specific version of the model | The model can change |\n| **Weights** | Internal “dials” (numbers the model can tune) | **Learning changes these** |\n| **Height** | “How wrong we are” as a number | Lower is better |\n| **Fog** | We don’t know the best answer in advance | Learning must be iterative |\n| **Slope underfoot** | Direction that reduces wrongness | Gives guidance |\n| **Step size** | How big each update is | Too big = unstable |\n| **Valley** | Best achievable model for this setup | There may be many valleys |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 2 — What is a Model? (Start with Simple Linear Regression)\n\n### What is this?\nA model is a function that maps inputs to outputs.\n\n### So what?\nIf you can’t describe what the model computes, “learning” becomes mystical.\n\n### What does this mean in practice?\nWe start with the simplest useful learnable model:\n\n\\[\n\\hat{y} = w \\cdot x + b\n\\]\n\nThis is called **Simple Linear Regression**.\n\n- \\(x\\): input  \n- \\(w\\): **weight** (a learnable number)  \n- \\(b\\): bias (a learnable offset)  \n- \\(\\hat{y}\\): prediction\n\n### Why should I care right now?\nA neural network is basically **many little linear regressions** chained together — plus activation functions."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Part 2 code: a model that does NOT learn yet\ndef predict_linear(x, w, b):\n    return w * x + b\n\nx = 3.0\nw = 2.0\nb = 1.0\n\nprint(\"Simple Linear Regression prediction:\", predict_linear(x, w, b))\nprint(\"Note: nothing learned yet — w and b are just numbers we picked.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 2.5 — Data Preprocessing: “Cleaning the Mountain”\n\n### What is this?\nData preprocessing transforms raw inputs into a form that is easier for models to learn from.\n\n### So what?\n**Garbage in, garbage out.**  \nBut even with “good” data, *scale* can make training unstable.\n\n### What does this mean in practice?\nIf one feature is in thousands and another is in single digits, the “mountain” becomes a steep canyon:\n- gradients can become unbalanced\n- the model “bounces” rather than converges\n\nA common fix is **normalization** (scaling features to a comparable range).\n\n### Why should I care right now?\nIf training behaves strangely (loss won’t go down, or is unstable), preprocessing is often the first place to look."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Simple normalization demo (0..1)\nimport numpy as np\n\nraw_sq_ft = np.array([1200, 2500, 800, 3200])\nraw_bedrooms = np.array([2, 4, 1, 5])\n\ndef normalize_0_1(data):\n    return (data - np.min(data)) / (np.max(data) - np.min(data))\n\nclean_sq_ft = normalize_0_1(raw_sq_ft)\nclean_bedrooms = normalize_0_1(raw_bedrooms)\n\nprint(\"Before (hard for hiker):\", raw_sq_ft[0], \"vs\", raw_bedrooms[0])\nprint(\"After  (easier to learn):\", round(float(clean_sq_ft[0]), 3), \"vs\", round(float(clean_bedrooms[0]), 3))\nprint(\"\\nSo what? Now both features are on similar scale, so weight updates behave more evenly.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 3 — Weights & Bias (What actually changes?)\n\n### What is this?\nWeights and bias are the **learnable parameters** of the model.\n\n### So what?\nIn ML, **nothing is learned except the weights (and bias)**.\n\n### What does this mean in practice?\n- **Training:** weights change to reduce loss  \n- **Inference:** weights are frozen and used for prediction\n\n### Why should I care right now?\nIf weights aren’t changing (or are changing in the wrong direction), learning has failed — even if code executes."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# \"Training vs inference\" shown explicitly\nw, b = 0.0, 0.0\nx = 3.0\n\nprint(\"Inference with initial weights:\", predict_linear(x, w, b))\n\n# Simulate training (weights updated)\nw, b = 2.0, 1.0\n\nprint(\"Inference with updated weights:\", predict_linear(x, w, b))\nprint(\"\\nKey point: training changes weights; inference uses weights unchanged.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 4 — Loss (Height on the Mountain)\n\n### What is this?\nLoss is a number that measures how wrong the model’s prediction is.\n\n### So what?\nLoss is the model’s **feedback**.  \nNo loss → no signal → no learning.\n\n### What does this mean in practice?\nWe compute loss by comparing prediction \\(\\hat{y}\\) to actual \\(y\\).\n\n### Why should I care right now?\nIf loss doesn’t decrease, the model is not learning — regardless of “reasonable” outputs."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Squared Error Loss (Regression)\n\n\\[\n\\text{loss} = (\\hat{y} - y)^2\n\\]\n\n**Why square it?**\n- avoids negative errors canceling\n- penalizes big mistakes more strongly"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Loss in code\ny_actual = 10.0\nw, b = 2.0, 1.0\ny_pred = predict_linear(3.0, w, b)\n\nloss = (y_pred - y_actual) ** 2\nprint(\"Prediction:\", y_pred)\nprint(\"Actual:\", y_actual)\nprint(\"Squared error loss:\", loss)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Loss vs Accuracy (don’t confuse them)\n\n- **Loss**: “how wrong?” (drives training)\n- **Accuracy**: “how often right?” (evaluation metric)\n\n**Hiker translation:**\n- Loss = height (how bad)\n- Accuracy = “am I closer?” (useful, but not a slope)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 5 — Gradient (Feeling the Slope)\n\n### What is this?\nA gradient tells us how loss changes when we change a weight slightly.\n\n### So what?\nGradient gives *direction* for learning. It answers: “Which way is downhill?”\n\n### What does this mean in practice?\nIf the gradient is positive, increasing the weight increases loss → decrease the weight (and vice versa).\n\n### Why should I care right now?\nWithout gradients, training is blind guessing."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import numpy as np\n\ndef loss_for_w(w, x=3.0, b=1.0, y=10.0):\n    y_hat = predict_linear(x, w, b)\n    return (y_hat - y) ** 2\n\n# Numerical gradient approximation\nw = 2.0\neps = 1e-5\ngrad_approx = (loss_for_w(w + eps) - loss_for_w(w - eps)) / (2 * eps)\n\nprint(\"Approx gradient d(loss)/d(w) at w=2.0:\", grad_approx)\nprint(\"Interpretation: if gradient > 0, decrease w to reduce loss.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 6 — Backpropagation (How gradients “flow back”)\n\n### What is this?\nBackpropagation is the algorithm that efficiently computes gradients for **all weights** in a multi-layer network.\n\n### So what?\nIn a deep network, there are thousands/millions of weights.  \nWe need a systematic way to determine **how each weight contributed to the final loss**.\n\n### What does this mean in practice?\nBackpropagation sends “credit/blame” backward through layers:\n- output layer → hidden layers → earlier layers\n- producing a gradient for each weight\n\n### Why should I care right now?\nIf gradients don’t reach earlier layers (or explode), learning stalls or becomes unstable.\n\n## Hiker story (decoded)\nImagine a **team of hikers** (layers). The final hiker measures “how wrong” they were at the finish.\nBackpropagation is like sending a **radio message backward** to everyone uphill:\n> “Here’s how much your last decision contributed to our final height. Adjust your dials accordingly.”"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 7 — Gradient Descent + Learning Rate (Taking steps)\n\n### What is this?\nGradient descent updates weights in the direction that reduces loss.\nLearning rate controls how big each update step is.\n\n### So what?\nThis is the training engine: **direction + step size**.\n\n### What does this mean in practice?\n\\[\nw \\leftarrow w - \\alpha \\cdot \\nabla_w \\text{loss}\n\\]\n\\(\\alpha\\) is the learning rate.\n\n### Why should I care right now?\n- Too large \\(\\alpha\\) → overshoot/diverge\n- Too small \\(\\alpha\\) → training appears “stuck”"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Train w and b on a tiny synthetic regression dataset using gradient descent (mechanics visible)\nimport numpy as np\n\nrng = np.random.default_rng(0)\nX = rng.uniform(-3, 3, size=120)\ntrue_w, true_b = 2.5, -0.7\nnoise = rng.normal(0, 0.8, size=X.shape)\nY = true_w * X + true_b + noise\n\ndef mse_loss(w, b, X, Y):\n    Y_hat = w * X + b\n    return np.mean((Y_hat - Y) ** 2)\n\ndef mse_grads(w, b, X, Y):\n    err = (w * X + b) - Y\n    dw = 2.0 * np.mean(err * X)\n    db = 2.0 * np.mean(err)\n    return dw, db\n\nw, b = 0.0, 0.0\nlr = 0.05\nlosses = []\n\nfor epoch in range(80):\n    loss = mse_loss(w, b, X, Y)\n    dw, db = mse_grads(w, b, X, Y)\n    w -= lr * dw\n    b -= lr * db\n    losses.append(loss)\n\nprint(\"Learned w, b:\", w, b)\nprint(\"Final loss:\", losses[-1])"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Plot loss curve (plain matplotlib defaults)\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(losses)\nplt.title(\"Loss over epochs (gradient descent)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE Loss\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 8 — Epochs, Validation, Overfitting (Generalisation is the real goal)\n\n### What is this?\n- **Epoch:** one full pass over training data\n- **Validation set:** a held-out “scout” dataset used during training to detect overfitting\n- **Overfitting:** training looks great, new data looks worse\n\n### So what?\nReal success is **not** low training loss. It’s good performance on data you didn’t train on.\n\n### What does this mean in practice?\nWe split data into:\n- Train (learn weights)\n- Validation (tune decisions; spot overfitting)\n- Test (final unbiased check)\n\n### Why should I care right now?\nOverfitting is a silent failure mode: you think you’ve succeeded until production."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Train/validation/test split and compare (simple demonstration)\nidx = np.arange(len(X))\nrng.shuffle(idx)\n\ntrain_idx = idx[:80]\nval_idx   = idx[80:100]\ntest_idx  = idx[100:]\n\nX_train, Y_train = X[train_idx], Y[train_idx]\nX_val,   Y_val   = X[val_idx],   Y[val_idx]\nX_test,  Y_test  = X[test_idx],  Y[test_idx]\n\nw, b = 0.0, 0.0\nlr = 0.05\ntrain_losses, val_losses = [], []\n\nfor epoch in range(120):\n    dw, db = mse_grads(w, b, X_train, Y_train)\n    w -= lr * dw\n    b -= lr * db\n    train_losses.append(mse_loss(w, b, X_train, Y_train))\n    val_losses.append(mse_loss(w, b, X_val, Y_val))\n\nprint(\"Final train loss:\", train_losses[-1])\nprint(\"Final val   loss:\", val_losses[-1])"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "plt.figure()\nplt.plot(train_losses, label=\"train\")\nplt.plot(val_losses, label=\"validation\")\nplt.title(\"Train vs Validation loss (watch for overfitting)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE Loss\")\nplt.legend()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**So what? How to read this plot**\n- If train loss keeps falling but validation loss rises: **overfitting**\n- If both are high and flat: **underfitting** (model too simple or not trained effectively)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 8.5 — Local Minima (Getting stuck in a pothole)\n\n### What is this?\nA **local minimum** is a “small valley” that is not the best valley overall.\n\n### So what?\nGradient descent can get stuck in a good-enough spot that isn’t the best possible.\n\n### What does this mean in practice?\nTraining may plateau early (loss stops improving) even though a better solution exists.\n\n### Why should I care right now?\nIt explains why changing:\n- initialization,\n- learning rate schedule,\n- optimizer,\n- or adding randomness\ncan lead to better results.\n\n## Hiker translation\nThe hiker finds a pothole on the way down and thinks they’re done — but a deeper valley exists elsewhere."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 9 — Deep Learning: A Team of Hikers (Neurons, Layers, Activations)\n\n### What is this?\nDeep Learning uses neural networks: many neurons arranged in layers.\n\n### So what?\nInstead of one hiker adjusting one set of dials, you have a **team**:\n- earlier hikers detect simple signals\n- later hikers combine them into more complex patterns\n\n### What does this mean in practice?\nA neuron computes:\n\\[\nz = w \\cdot x + b,\\quad \\text{output} = \\text{activation}(z)\n\\]\n\n### Why should I care right now?\nThis is why “deep” learning is just scaled-up learning:\n- more weights → more power\n- more weights → more ways to fail (needs good loss/gradients/preprocessing)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Activation Functions\n\n### What is this?\nAn activation function introduces **non-linearity**.\n\n### So what?\nWithout non-linearity, stacking layers collapses into a single linear model.\n\n### What does this mean in practice?\nCommon activations:\n- ReLU: `max(0, z)`\n- Sigmoid: squashes to 0..1\n\n### Why should I care right now?\nActivation choice affects:\n- whether gradients flow\n- how quickly models learn"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Visualize ReLU and Sigmoid\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef relu(z):\n    return np.maximum(0, z)\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\nz = np.linspace(-6, 6, 200)\n\nplt.figure()\nplt.plot(z, relu(z), label=\"ReLU\")\nplt.plot(z, sigmoid(z), label=\"Sigmoid\")\nplt.title(\"Activation functions\")\nplt.xlabel(\"z\")\nplt.ylabel(\"activation(z)\")\nplt.legend()\nplt.show()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Part 9.5 — A \"Team of Hikers\" in code: a tiny dense layer\nimport numpy as np\n\ndef relu(z):\n    return np.maximum(0, z)\n\nx = np.array([1.5])  # one input signal\n\n# 3 neurons (3 hikers) each with their own weight and bias\nweights = np.array([0.8, -0.5, 1.2])\nbiases  = np.array([0.1, 0.5, -0.2])\n\nz = x * weights + biases\na = relu(z)\n\nprint(\"Input:\", x)\nprint(\"Pre-activation (z):\", z)\nprint(\"Post-activation (ReLU):\", a)\n\nprint(\"\\nSo what?\")\nprint(\"- Each neuron computes a small linear model (w*x+b)\")\nprint(\"- ReLU filters (some outputs become 0), helping the network ignore noise\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 10 — Training vs Inference (Final unifying summary)\n\n### What is this?\n- **Training:** adjust weights to reduce loss\n- **Inference:** freeze weights and make predictions\n\n### So what?\nThis is the lifecycle of every ML/DL system.\n\n### What does this mean in practice?\nWhen something fails, ask:\n- Are we training correctly (loss decreasing)?\n- Are we overfitting (validation rising)?\n- Are we using the correct weights/version in inference?\n\n### Why should I care right now?\nMost production failures come from train/inference mismatch.\n\n---\n\n## Final story recap\n1. We start with a model (hiker) and weights (internal dials).\n2. We measure wrongness (loss = height).\n3. We find direction (gradient = slope).\n4. We update weights carefully (learning rate = step size).\n5. We repeat (epochs), and validate (scout set) to avoid overfitting.\n6. We accept we can get stuck (local minima).\n7. Deep learning is the same story with a **team of hikers** (layers).\n\n> **Machine learning is walking downhill in fog using feedback, not sight.**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# End-of-Module Resources\n\n- [Hiker's Cheat Sheet](Module4_Hiker_CheatSheet.md) — Your quick reference for translating between the story and technical terms\n- [Knowledge Checks (5 questions)](Module4_Knowledge_Checks.md) — Answer in plain English to confirm understanding"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}